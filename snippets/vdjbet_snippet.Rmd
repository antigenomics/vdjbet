---
title: "VDJbet snippet"
author: "M.S."
date: "2025-03-14"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stringr)
library(ggplot2)
set.seed(42)
```

Generate random sequences

```{bash}
olga-generate_sequences --humanTRB --seed 42 -n 10000000 | gzip -c > olga/olga10000000.tsv.gz
```

Load them

```{r}
data.olga <- read_tsv("../assets/olga/olga10000000.tsv.gz",
                      col_names = c("junction", "junction_aa", "v_call", "j_call")) |>
  mutate(duplicate_count = 1)
```

Load vaccination data

```{r}
strip_gene <- function(gene_call) {
  str_split_fixed(gene_call, fixed("*"), 2)[,1]
}

meta.yf <- read_tsv("../assets/yf2019/metadata.txt")
data.yf <- meta.yf |>
  group_by(donor, day, replica) |>
  group_modify(~read_tsv(paste0("yf2019/", .$file_name)) |>
                 select(junction = `N. Seq. CDR3`,
                        junction_aa = `AA. Seq. CDR3`,
                        v_call = `All V hits`,
                        j_call = `All J hits`,
                        duplicate_count = `Clone count`
                        ) |>
                 mutate(v_call = strip_gene(v_call),
                        j_call = strip_gene(j_call))
               )
```

Compute VJ usage factor $\phi = P_{data}(\text V , \text J) /  P_{model}(\text V , \text J)$ so that we can later
use it to calculate $P_{data}(\text{CDR3aa}, \text V , \text J) = \phi(\text V , \text J) P_{model} (\text{CDR3aa})$

```{r}
data.vj <- data.yf |>
  group_by(v_call, j_call) |>
  summarise(vj_count_yf = n()) |>
  full_join(data.olga |>
              group_by(v_call, j_call) |>
              summarise(vj_count_olga = n())) |>
  mutate(vj_count_yf = ifelse(is.na(vj_count_yf), 0, vj_count_yf) + 1,
         vj_count_olga = ifelse(is.na(vj_count_olga), 0, vj_count_olga) + 1,
         vj_factor = vj_count_yf / sum(vj_count_yf) *
           sum(vj_count_olga) / vj_count_olga)

data.vj |>
  arrange(vj_factor) |>
  head()

data.vj |>
  arrange(-vj_factor) |>
  head()

data.vj |>
  ggplot(aes(x = vj_count_yf, y = vj_count_olga)) +
  geom_smooth(method = "lm") +
  geom_point(aes(color = log2(vj_factor))) +
  scale_color_distiller(palette = "Spectral",
                        limits = c(-1.5, 1.5)) +
  scale_x_log10() + scale_y_log10() +
  theme_bw()
```

Load VDJdb data and select YFV

```{r}
data.vdjdb <- read_tsv("../assets/vdjdb-2025-02-21/vdjdb_full.txt") |>
  filter(antigen.epitope == "LLWNGPMAV", !is.na(cdr3.beta)) |>
  select(v_call = v.beta, j_call = j.beta, junction_aa = cdr3.beta) |>
  mutate(v_call = strip_gene(v_call),
         j_call = strip_gene(j_call),
         junction = strrep('N', 3 * nchar(junction_aa)),
         duplicate_count = 1) |>
  unique()
```

Write seqs we want to compute rearrangement probability for. We will use
a separate PBMC 5'RACE dataset for it in order to remove intrinsic biases of
OLGA generation model (presence/absence of spurios sequences prior to selection).

```{r}
v_allowed <- unique(data.olga$v_call)
j_allowed <- unique(data.olga$j_call)

#data.probes <- bind_rows(data.vdjdb,
#                         data.yf |> # (!) correct for markers originating from data
#                           ungroup() |>
#                           sample_n(100000)) |>
#  filter(v_call %in% v_allowed, j_call %in% j_allowed)

data.britanova <- read_tsv("../assets/britanova/human.trb.strict.txt.gz") |>
  select(junction_aa = cdr3aa,
         v_call = v, j_call = j)

data.probes <- bind_rows(data.vdjdb,
                         data.britanova |>
                           head(100000)) |>
  filter(v_call %in% v_allowed, j_call %in% j_allowed)

data.probes |>
  select(junction_aa, v_call, j_call) |>
  unique() |>
  write_tsv("../assets/olga/probes.tsv", col_names = F)
```

Run OLGA, approx 10 min per 100000 seqs

```{bash}
rm olga/probes_pgen.tsv
olga-compute_pgen -i olga/probes.tsv --humanTRB -o olga/probes_pgen.tsv --display_off --time_updates_off --seq_in 0 --v_in 1 --j_in 2
```

Load $P$ from OLGA output

```{r}
data.probes |>
  select(-junction, -duplicate_count) |>
  unique() |>
  left_join(read_tsv("../assets/olga/probes_pgen.tsv", 
                     col_names = c("junction_aa", "pcdr"))) |>
  left_join(data.vdjdb |>
              select(v_call, j_call, junction_aa) |>
              mutate(vdjdb = T))|>
  mutate(vdjdb = ifelse(is.na(vdjdb), F, T)) |>
  left_join(data.vj |>
              select(v_call, j_call, vj_factor)) |>
  group_by(v_call, j_call, junction_aa) |>
  mutate(pcdr = max(pcdr)) |> # somewhy different Pgens can be returned?
  unique() |>
  mutate(pgen = pcdr * vj_factor + 2^-60,
         pgen_bin = round(log2(pgen), 0)) -> data.probes.pgen

data.probes.pgen |>
  arrange(-pgen_bin) |>
  head(n=100)
```

Compare distribution of $P$ between VDJdb and random sample

```{r}
data.probes.pgen |>
  ggplot(aes(x = pgen_bin)) +
  geom_histogram(binwidth = 1, 
                 aes(fill = vdjdb, y = ..density..),
                 position = "dodge") +
  geom_density(aes(color = vdjdb, y = ..density..)) +
  scale_fill_brewer(palette = "Paired") +
  scale_color_brewer(palette = "Paired") +
  theme_bw()
```

Do 200 bootstraps and see how much we match

```{r}
data.probes.pgen |>
  filter(vdjdb) |>
  group_by(pgen_bin) |>
  summarise(count_vdjdb = n()) ->
  vdjdb_pgen_counts

data.probes.pgen |>
  filter(vdjdb) |>
  group_by()

sum(vdjdb_pgen_counts$count_vdjdb)

data.probes.pgen.pool <- data.probes.pgen |>
  left_join(vdjdb_pgen_counts) |>
  filter(!vdjdb, !is.na(count_vdjdb))

data.yf.match <- data.yf |>
  inner_join(data.vdjdb |>
               select(v_call, j_call, junction_aa)) |>
  group_by(donor, day, replica) |>
  summarise(matched = n(), 
            matched_duplicate_count = sum(duplicate_count)) |>
  mutate(bootstrap = 0)
for (iter in 1:200){
  print(paste0("Bootstrap iter#", iter))
  data.probes.pgen.pool |>
    group_by(pgen_bin) |>
    sample_n(count_vdjdb[1]) |>
    select(v_call, j_call, junction_aa) -> data.probes.pgen.sample
  data.yf.match <- rbind(data.yf.match,
                         data.yf |>
                           inner_join(data.probes.pgen.sample) |>
                           group_by(donor, day, replica) |>
                           summarise(matched = n(), 
                                     matched_duplicate_count = sum(duplicate_count)) |>
                           mutate(bootstrap = iter)
  )
}
```

Plot dynamics of specific clonotypes and cells

```{r}
data.yf.match |>
  filter(bootstrap == 0) |>
  ggplot(aes(x = day, y = matched)) +
  geom_boxplot(data = data.yf.match |>
                 filter(bootstrap > 0),
               aes(x = day, 
                   group = day,
                   y = matched), 
               width = 3, 
               outlier.size = 1) +
  geom_line(color = "red") +
  geom_point(color = "red") +
  facet_grid(replica~donor) +
  theme_bw()

data.yf.match |>
  filter(bootstrap == 0) |>
  ggplot(aes(x = day, y = log2(matched_duplicate_count + 1))) +
  geom_boxplot(data = data.yf.match |>
                 filter(bootstrap > 0),
               aes(x = day, group = day,
                   y = log2(matched_duplicate_count + 1)), 
               width = 3, 
               outlier.size = 1) +
  geom_line(color = "red") +
  geom_point(color = "red") +
  facet_grid(replica~donor) +
  theme_bw()
```

Compute bootstrapped mean and sd and to stat tests

```{r}
data.yf.match |>
  group_by(donor, day, replica) |>
  summarise(matched_mean = mean(matched[bootstrap > 0]),
            matched_sd = sd(matched[bootstrap > 0]),
            matched_p = 1 - sum(matched[bootstrap == 0] > matched) / n(),
            matched = matched[bootstrap == 0],
            matched_duplicate_count_mean = mean(log2(matched_duplicate_count[bootstrap > 0] + 1)),
            matched_duplicate_count_sd = sd(log2(matched_duplicate_count[bootstrap > 0] + 1)),
            matched_duplicate_count_p = 1 - sum(matched_duplicate_count[bootstrap == 0] > matched_duplicate_count) / n(),
            matched_duplicate_count = log2(matched_duplicate_count[bootstrap == 0] + 1),
            matched_cohen_d = (matched - matched_mean) / matched_sd,
            matched_duplicate_count_cohen_d = (matched_duplicate_count - matched_duplicate_count_mean) / matched_duplicate_count_sd) |>
  mutate(matched_p_adj = p.adjust(matched_p, method = "fdr"),
         matched_duplicate_count_p_adj = p.adjust(matched_duplicate_count_p, method = "fdr")) -> data.yf.match.stat

data.yf.match.stat
```

Plot effect size and significance

```{r}
data.yf.match.stat |>
  ggplot(aes(x = as.factor(day), 
             y = paste(donor, replica),
             fill = matched_cohen_d,
             color = matched_p_adj < 0.1 & 
               matched_cohen_d > 0)) +
  geom_tile(size = 1) +
  scale_color_manual(guide = "none",
                     values = c("white", "black")) +
  scale_fill_distiller("Clonotypes matched\nCohen's d", 
                       palette = "RdBu", 
                       direction = -1,
                       limits = c(-6, 6)) +
  xlab("day") + 
  ylab("sample") +
  theme_classic() +
  theme(aspect.ratio = 1,
        legend.position = "bottom")

data.yf.match.stat |>
  ggplot(aes(x = as.factor(day), 
             y = paste(donor, replica),
             fill = matched_duplicate_count_cohen_d,
             color = matched_duplicate_count_p_adj < 0.1 & 
               matched_duplicate_count_cohen_d > 0)) +
  geom_tile(size = 1) +
  scale_color_manual(guide = "none",
                     values = c("white", "black")) +
  scale_fill_distiller("Cells matched\nCohen's d", 
                       palette = "Reds", 
                       direction = 1) +
  xlab("day") + 
  ylab("sample") +
  theme_classic() +
  theme(aspect.ratio = 1,
        legend.position = "bottom")
```

```{r}
# TODO: COVID example (single-cell?)
```
